% ==============================================================================================================================================================
% Reinforcement Learning
% ==============================================================================================================================================================

% Deep Q-learning
@article{mnih2015,
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    issn = {00280836},
    journal = {Nature},
    title = {Human-level control through deep reinforcement learning},
    year = {2015}
}

% DreamerV2
@inproceedings{hafner2021,
    title={Mastering Atari with Discrete World Models},
    author={Danijar Hafner and Timothy P Lillicrap and Mohammad Norouzi and Jimmy Ba},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2021},
}

% DreamerV3
@article{hafner2025,
    author       = {Danijar Hafner and Jurgis Pasukonis and Jimmy Ba and Timothy Lillicrap},
    title        = {Mastering diverse control tasks through world models},
    journal      = {Nature},
    year         = {2025},
    doi          = {10.1038/s41586-025-08744-2}
}

% AlphaGo
@article{silver2016,
  author    = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  year      = {2016},
  doi       = {10.1038/nature16961},
}

% AlphaZero
@article{silver2018,
    author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
    title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
    journal = {Science},
    year = {2018},
    doi = {10.1126/science.aar6404},
}

% MuZero
@article{schrittwieser2020,
  author    = {Julian Schrittwieser and Ioannis Antonoglou and Thomas Hubert and Karen Simonyan and Laurent Sifre and Simon Schmitt and Arthur Guez and Edward Lockhart and Demis Hassabis and Thore Graepel and Timothy Lillicrap and David Silver},
  title     = {Mastering Atari, Go, chess and shogi by planning with a learned model},
  journal   = {Nature},
  year      = {2020},
  doi       = {10.1038/s41586-020-03051-4},
}

% MuZero Reanalyze
@inproceedings{schrittwieser2021,
    author = {Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
    title = {Online and offline reinforcement learning by planning with a learned model},
    year = {2021},
    isbn = {9781713845393},
    booktitle = {International Conference on Neural Information Processing Systems (NeurIPS)},
}

% EfficientZero
@inproceedings{ye2021,
    author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
    booktitle = {International Conference on Neural Information Processing Systems (NeurIPS)},
    title = {Mastering Atari Games with Limited Data},
    year = {2021}
}

% ==============================================================================================================================================================
% Tools
% ==============================================================================================================================================================

% LLVM
@inproceedings{lattner2004,
    author={Lattner, C. and Adve, V.},
    booktitle={International Symposium on Code Generation and Optimization (CGO)}, 
    title={LLVM: a compilation framework for lifelong program analysis and transformation}, 
    year={2004},
    doi={10.1109/CGO.2004.1281665}
}

% CompilerGym
@inproceedings{cummins2022,
    author = {Cummins, Chris and Wasti, Bram and Guo, Jiadong and Cui, Brandon and Ansel, Jason and Gomez, Sahir and Jain, Somya and Liu, Jia and Teytaud, Olivier and Steiner, Benoit and Tian, Yuandong and Leather, Hugh},
    title = {CompilerGym: robust, performant compiler optimization environments for AI research},
    year = {2022},
    doi = {10.1109/CGO53902.2022.9741258},
    booktitle = {International Symposium on Code Generation and Optimization (CGO)},
}

% ==============================================================================================================================================================
% Datasets
% ==============================================================================================================================================================

% MiBench
@inproceedings{guthaus2001,
    author={Guthaus, M.R. and Ringenberg, J.S. and Ernst, D. and Austin, T.M. and Mudge, T. and Brown, R.B.},
    booktitle={IEEE International Workshop on Workload Characterization (WWC)}, 
    title={MiBench: A free, commercially representative embedded benchmark suite}, 
    year={2001},
    doi={10.1109/WWC.2001.990739}
}

% cBench
@inproceedings{fursin2014,
    title={Collective Tuning Initiative}, 
    author={Grigori Fursin},
    booktitle={GCC Developers Summit},
    year={2009},
}

% AnghaBench
@inproceedings{dasilva2021,
    author = {da Silva, Anderson Faustino and Kind, Bruno Conde and de Souza Magalh\~{a}es, Jos\'{e} Wesley and Rocha, Jer\^{o}nimo Nunes and Guimar\~{a}es, Breno Campos Ferreira and Pereira, Fernando Magno Quint\~{a}o},
    title = {AnghaBench: a suite with one million compilable C benchmarks for code-size reduction},
    year = {2021},
    doi = {10.1109/CGO51591.2021.9370322},
    booktitle = {International Symposium on Code Generation and Optimization (CGO)},
}

% CodeContests (AlphaCode)
@article{li2022,
    author = {Yujia Li  and David Choi  and Junyoung Chung  and Nate Kushman  and Julian Schrittwieser  and Rémi Leblond  and Tom Eccles  and James Keeling  and Felix Gimeno  and Agustin Dal Lago  and Thomas Hubert  and Peter Choy  and Cyprien de Masson d’Autume  and Igor Babuschkin  and Xinyun Chen  and Po-Sen Huang  and Johannes Welbl  and Sven Gowal  and Alexey Cherepanov  and James Molloy  and Daniel J. Mankowitz  and Esme Sutherland Robson  and Pushmeet Kohli  and Nando de Freitas  and Koray Kavukcuoglu  and Oriol Vinyals },
    title = {Competition-level code generation with AlphaCode},
    journal = {Science},
    year = {2022},
    doi = {10.1126/science.abq1158},
}

% CHStone
@inproceedings{hara2008,
    author={Yuko Hara and Hiroyuki Tomiyama and Shinya Honda and Hiroaki Takada and Katsuya Ishii},
    booktitle={International Symposium on Circuits and Systems (ISCAS)}, 
    title={CHStone: A benchmark program suite for practical C-based high-level synthesis}, 
    year={2008},
    doi={10.1109/ISCAS.2008.4541637}
}

% Tensorflow
@inproceedings{abadi2016,
    author = {Abadi, Mart\'{\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
    title = {TensorFlow: a system for large-scale machine learning},
    year = {2016},
    isbn = {9781931971331},
    booktitle = {USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
}

% SPEC CPU2017
@inproceedings{bucek2018,
    author = {Bucek, James and Lange, Klaus-Dieter and v. Kistowski, J\'{o}akim},
    title = {SPEC CPU2017: Next-Generation Compute Benchmark},
    year = {2018},
    doi = {10.1145/3185768.3185771},
    booktitle = {International Conference on Performance Engineering (ICPE)},
}

% Jotai
@article{kind2025,
    title = {Jotai: A methodology for the generation of executable C benchmarks},
    journal = {Journal of Computer Languages},
    year = {2025},
    doi = {10.1016/j.cola.2025.101368},
    author = {Cecília Conde Kind and Michael Canesche and Fernando Magno Quintão Pereira},
}

% ==============================================================================================================================================================
% Machine Learning for Compiler Optimization
% ==============================================================================================================================================================

% AutoPhase
@inproceedings{hajali2020,
    author = {Haj-Ali, Ameer and Huang, Qijing (Jenny) and Xiang, John and Moses, William and Asanovic, Krste and Wawrzynek, John and Stoica, Ion},
    booktitle = {Machine Learning and Systems (MLSys)},
    title = {AutoPhase: Juggling HLS Phase Orderings in Random Forests with Deep Reinforcement Learning},
    year = {2020}
}

% CORL
@inproceedings{mammadli2020,
    author={Mammadli, Rahim and Jannesari, Ali and Wolf, Felix},
    booktitle={Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC) and Workshop on Hierarchical Parallelism for Exascale Computing (HiPar)}, 
    title={Static Neural Compiler Optimization via Deep Reinforcement Learning}, 
    year={2020},
    doi={10.1109/LLVMHPCHiPar51896.2020.00006}
}

% POSET-RL
@inproceedings{jain2022,
    author={Jain, Shalini and Andaluri, Yashas and VenkataKeerthy, S. and Upadrasta, Ramakrishna},
    booktitle={IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
    title={POSET-RL: Phase ordering for Optimizing Size and Execution Time using Reinforcement Learning}, 
    year={2022},
    doi={10.1109/ISPASS55109.2022.00012}
}

% DeCOS
@inproceedings{cui2025,
    author = {Cui, Tianming and Yew, Pen-Chung and McCamant, Stephen and Zhai, Antonia},
    title = {DeCOS: Data-Efficient Reinforcement Learning for Compiler Optimization Selection Ignited by LLM},
    year = {2025},
    doi = {10.1145/3721145.3725765},
    booktitle = {International Conference on Supercomputing (ICS)},
}

% Review
@article{wang2018,
  author={Wang, Zheng and O’Boyle, Michael},
  journal={IEEE}, 
  title={Machine Learning in Compiler Optimization}, 
  year={2018},
  doi={10.1109/JPROC.2018.2817118}
}

% CompilerDream
@inproceedings{chaoyi2025,
    author = {Deng, Chaoyi and Wu, Jialong and Feng, Ningya and Wang, Jianmin and Long, Mingsheng},
    title = {CompilerDream: Learning a Compiler World Model for General Code Optimization},
    year = {2025},
    doi = {10.1145/3711896.3736887},
    booktitle = {Conference on Knowledge Discovery and Data Mining (KDD)},
}

% ==============================================================================================================================================================
% Program Representation
% ==============================================================================================================================================================

% inst2vec
@inproceedings{bennun2018,
    author = {Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten},
    title = {Neural code comprehension: a learnable representation of code semantics},
    year = {2018},
    booktitle = {International Conference on Neural Information Processing Systems (NeurIPS)},
}